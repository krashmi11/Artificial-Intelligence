{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":500,"status":"ok","timestamp":1712476068692,"user":{"displayName":"A1_11_Rashmi Kanharkar","userId":"08282267267285676020"},"user_tz":-330},"id":"KrrfH_5JUqsx","outputId":"2c08ec45-9800-47a9-9103-eff207d3a366"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.0\n","0.0\n","0.0\n","\n","\n","0.0\n","0.0\n","0.0\n","\n","\n","0.0\n","0.0\n","0.0\n","\n","\n","-1.0\n","0.0\n","0.0\n","\n","\n",">epoch=0, lrate=1.000, error=1.000\n","0.0\n","1.0\n","1.0\n","\n","\n","0.0\n","1.0\n","1.0\n","\n","\n","0.0\n","1.0\n","1.0\n","\n","\n","-1.0\n","1.0\n","1.0\n","\n","\n",">epoch=1, lrate=1.000, error=2.000\n","-1.0\n","1.0\n","1.0\n","\n","\n","-1.0\n","1.0\n","1.0\n","\n","\n","-1.0\n","1.0\n","1.0\n","\n","\n","-1.0\n","1.0\n","1.0\n","\n","\n",">epoch=2, lrate=1.000, error=0.000\n","-1.0\n","1.0\n","1.0\n","\n","\n","-1.0\n","1.0\n","1.0\n","\n","\n","-1.0\n","1.0\n","1.0\n","\n","\n","-1.0\n","1.0\n","1.0\n","\n","\n",">epoch=3, lrate=1.000, error=0.000\n","-1.0\n","1.0\n","1.0\n","\n","\n","-1.0\n","1.0\n","1.0\n","\n","\n","-1.0\n","1.0\n","1.0\n","\n","\n","-1.0\n","1.0\n","1.0\n","\n","\n",">epoch=4, lrate=1.000, error=0.000\n","[-1.0, 1.0, 1.0]\n"]}],"source":["# Make a prediction with weights\n","def predict(row, weights):\n","\tactivation = weights[0]\n","\tfor i in range(len(row)-1):\n","\t\tactivation += weights[i + 1] * row[i]\n","\treturn 1.0 if activation >= 0.0 else 0.0\n","\n","# Estimate Perceptron weights using stochastic gradient descent\n","def train_weights(train, l_rate, n_epoch):\n","    weights = [0.0 for i in range(len(train[0]))]\n","    # weights[0]=0.3\n","    # weights[1]=0.1\n","    # weights[2]=0.5\n","    for epoch in range(n_epoch):\n","        sum_error = 0.0\n","        for row in train:\n","            prediction = predict(row, weights)\n","            error = row[-1] - prediction\n","            sum_error += error ** 2  # Accumulate the squared error\n","            weights[0] += l_rate * error  # Update bias\n","            print(weights[0])\n","            for i in range(len(weights)-1):  # Update weights for features\n","                weights[i + 1] += l_rate * error * row[i]\n","                print(weights[i+1])\n","            print(\"\\n\")\n","        print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))\n","\n","    return weights\n","\n","\n","# Calculate weights\n","\n","dataset=[\n","    [1,1,1],\n","    [1,0,1],\n","    [0,1,1],\n","    [0,0,0]\n","\n","]\n","l_rate = 1\n","n_epoch = 5\n","weights = train_weights(dataset, l_rate, n_epoch)\n","print(weights)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":551,"status":"ok","timestamp":1712476107722,"user":{"displayName":"A1_11_Rashmi Kanharkar","userId":"08282267267285676020"},"user_tz":-330},"id":"CHGOdUdWbfFl","outputId":"b1be76df-2c79-46bd-80d6-c0468e9d1861"},"outputs":[{"name":"stdout","output_type":"stream","text":["Expected=1, Predicted=1\n","Expected=1, Predicted=1\n","Expected=1, Predicted=1\n","Expected=0, Predicted=0\n"]}],"source":["# Make a prediction with weights\n","def predict(row, weights):\n","\tactivation = weights[0]\n","\tfor i in range(len(row)-1):\n","\t\tactivation += weights[i + 1] * row[i]\n","\treturn 1.0 if activation >= 0.0 else 0.0\n","\n","dataset=[\n","    [1,1,1],\n","    [1,0,1],\n","    [0,1,1],\n","    [0,0,0]\n","\n","]\n","weights = [-1.0, 1.0, 1.0]\n","for row in dataset:\n","\tprediction = predict(row, weights)\n","\tprint(\"Expected=%d, Predicted=%d\" % (row[-1], prediction))"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOTgrkAWQ7xo2EspcLbpEJT","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":0}
